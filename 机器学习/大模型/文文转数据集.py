import json
from random import randint
from openai import OpenAI


with open('config.json') as f:
    cfg = json.load(f)

# å…¨å±€å‚æ•°
CHUNK_SIZE = 800  # æ¯æ®µæœ€å¤š 800 å­—

# APIå’Œè¾“å‡ºæ–‡ä»¶é…ç½®ï¼ˆgpt-4oé€Ÿåº¦å¿«ï¼Œç­”æ¡ˆä¸°å¯Œï¼Œä»·æ ¼è´µã€‚deepseeké€Ÿåº¦æ…¢ï¼Œç­”æ¡ˆè¾ƒå°‘ï¼Œä»·æ ¼ä¾¿å®œï¼‰
# api_key = cfg['DEEPSEEK_API_KEY']
# base_url="https://api.deepseek.com"
# model_name="deepseek-chat" # deepseekæå–çš„æ•°æ®é›†è´¨é‡å¾ˆä½ï¼Œå®¹æ˜“èƒ¡ä¹±ç¼–é€ ã€‚

base_url="https://api.laozhang.ai/v1"
api_key = cfg['OpenAI_API_KEY']
model_name= "gpt-4.1"

# base_url="https://generativelanguage.googleapis.com/v1beta/openai/"
# api_key = cfg['Gemini_API_KEY']
# model_name="gemini-2.5-flash"

output_file = f"output/dataset_{model_name}_temp1.md"


# å°†æ–‡ç« æ–‡æœ¬å°½é‡å¹³å‡åˆ†æˆå¤šä¸ªç‰‡æ®µï¼Œæ¯ç‰‡æœ€å¤š CHUNK_SIZE å­—
def split_into_chunks(text, max_chars=CHUNK_SIZE):
    total_len = len(text)
    if total_len <= max_chars:
        return [text.strip()]

    # ä¼°ç®—éœ€è¦å¤šå°‘æ®µï¼Œç¡®ä¿æ¯æ®µä¸è¶…è¿‡max_charsã€‚(å…ˆå¯¹æ–‡ç« åˆ†æˆ2ç»„ï¼Œæ£€æŸ¥æ¯ç»„æ˜¯å¦è¶…è¿‡max_charsä¸ªå­—ï¼Œå¦‚æœè¶…è¿‡äº†ï¼Œå°±åˆ†æˆ3ç»„ï¼Œç»§ç»­æ£€æŸ¥ï¼Œä»¥æ­¤ç±»æ¨ï¼Œç›´åˆ°æ¯ç»„ä¸è¶…è¿‡max_charså­—)
    num_chunks = 2
    while total_len / num_chunks > max_chars:
        num_chunks += 1
    approx_len = (total_len // num_chunks) + randint(-50, 50)  # å¢åŠ éšæœºæ€§ï¼Œé¿å…åŒä¸€ç¯‡æ–‡ç« æ¯æ¬¡åˆ†å‰²ç»“æœå®Œå…¨ä¸€æ ·

    paragraphs = [p.strip() for p in text.split("\n") if p.strip()]
    chunks = []
    current = ""

    for i, para in enumerate(paragraphs):
        if len(current) + len(para) + randint(40, 60) <= approx_len:  # æ·»åŠ ä¸€ä¸ªéšæœºå®‰å…¨è¾¹ç•Œï¼Œé¿å…æ®µè½è¿‡é•¿
            current += para + "\n"
        else:
            chunks.append(current.strip())
            current = para + "\n"

            # âœ… æ™ºèƒ½æå‰ç»ˆæ­¢åˆ¤æ–­ï¼ˆæ¯”å¦‚è¦æ‹†åˆ†æˆ3ç»„ï¼Œå¦‚æœchunksåˆ—è¡¨ä¸­å·²ç»æœ‰ä¸¤ç»„æ•°æ®äº†ï¼Œå°±ç›´æ¥æŠŠå‰©ä¸‹çš„æ–‡æœ¬å½“æˆæœ€åä¸€ç»„ï¼Œè¿™ç§åˆ¤æ–­å¯é¿å…åœ¨ç‰¹æ®Šæƒ…å†µä¸‹å¤šæ‹†åˆ†ä¸€æ¬¡ï¼‰
            if len(chunks) == num_chunks - 1:
                # å‰©ä¸‹çš„æ‰€æœ‰æ®µè½åˆå¹¶ä¸ºæœ€åä¸€ç»„
                remaining_text = "\n".join(paragraphs[i+1:]).strip()
                if remaining_text:
                    current += remaining_text
                break

    if current:
        chunks.append(current.strip())

    return chunks


# å‘æ¨¡å‹å‘é€è¯·æ±‚ï¼Œä¿æŒä¸Šä¸‹æ–‡å¯¹è¯
def process_article_chunks(chunks):
    messages = [
        {"role": "system", "content": system_prompt}
    ]
    all_output = []
    chunks_num = len(chunks)
    for i, chunk in enumerate(chunks):
        print(f'[å¤„ç†ç‰‡æ®µ] {i + 1}/{chunks_num}: {chunk[:50] + '...'}')  # æ‰“å°ç‰‡æ®µå‰50ä¸ªå­—ç¬¦
        messages.append({"role": "user", "content": f"ã€æ–‡ç« ç‰‡æ®µå¼€å§‹ã€‘\n{chunk}\nã€æ–‡ç« ç‰‡æ®µç»“æŸã€‘"})
        response = client.chat.completions.create(
            model=model_name,
            messages=messages,
            stream=False,           # é™æ€æ•°æ®å¤„ç†å…³é—­æµå¼è¾“å‡ºï¼Œæ›´æ–¹ä¾¿ç›´æ¥è·å–å®Œæ•´ç»“æœã€‚
            temperature = 0.9,      # æ§åˆ¶ç”Ÿæˆå¤šæ ·æ€§ã€‚(ä½¿ç”¨gpt-4oæ—¶ï¼Œtemperatureè¾¾åˆ°1.3ä¼šå‡ºç°ä¹±ç )
            top_p=1,                # æ§åˆ¶è¯æ±‡é‡‡æ ·èŒƒå›´ã€‚ ä¿æŒä¸º1ï¼Œæ§åˆ¶éšæœºæ€§çš„ä¸»è¦ç”¨ temperature
            presence_penalty=0.0,   # è®¾ç½®ä¸ºæ­£å€¼ä¼šé¼“åŠ±æ¨¡å‹ä¸è¦ä¸€å‘³é‡å¤å·²æœ‰å†…å®¹ï¼Œç¨å¾®é¼“åŠ±è¾“å‡ºæ›´å¤šä¸åŒä¿¡æ¯
            frequency_penalty=0.0,  # ä¸æŠ‘åˆ¶é‡å¤ï¼ˆå› ä¸ºé—®ç­”ç»“æ„é‡å¤æ˜¯æ­£å¸¸çš„ï¼‰
            max_tokens = 2048       # è®¾ç½®ä¸º 2048 æˆ–æ›´é«˜ï¼Œä»¥å…å›ç­”è¢«æˆªæ–­
        )
        reply = response.choices[0].message.content.strip()
        messages.append({"role": "assistant", "content": reply})
        all_output.append(reply)
    return all_output

# ä¿å­˜æ•°æ®é›†åˆ°æ–‡ä»¶
def save_dataset(article_text, output_path):
    with open(output_path, "a", encoding="utf-8") as f:
        chunks = split_into_chunks(article_text)
        qa_outputs = process_article_chunks(chunks)
        for qa in qa_outputs:
            f.write(qa + "\n\n")
    print(f"\nğŸ‰ å¤„ç†å®Œæˆï¼Œæ•°æ®å·²ä¿å­˜åˆ°ï¼š{output_path}")



# åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯
client = OpenAI(api_key=api_key, base_url=base_url)
# è¯»å–ç³»ç»Ÿæç¤ºè¯
with open('system_prompt.md', "rt", encoding="utf-8") as f:
    system_prompt = f.read().strip()


article_text = """
äººç±»çš„æ„è¯†ç”±è®¯æ¯æ„æˆï¼ŒæŠŠä¸€ä¸ªäººçš„ç²¾ç¥æ„è¯†è®¯æ¯å®Œæ•´çš„è½¬ç§»åˆ°ä¸€ä¸ªæ–°çš„è½½ä½“é‡Œå¤æ´»ï¼Œè¿™æ ·çš„äººå°±ä¼šæºå¸¦æœ‰å®Œæ•´çš„å‰ä¸–è®°å¿†æ¥åˆ°è¿™ä¸ªä¸–ç•Œï¼Œè¿™å°±æ˜¯è½¬ç”Ÿã€‚è€Œè¿™ä¸ªè¿‡ç¨‹ä¸­ï¼Œæœ‰ä¸ªæœ€é‡è¦çš„ç§‘æŠ€é“å…·ï¼Œå°±æ˜¯çµé­‚ã€‚

çµé­‚è¿™ä¸ªè¯åœ¨æ–‡å­¦ä¸­çš„å«ä¹‰æ˜¯æŸä»¶äº‹ç‰©çš„æœ¬è´¨å’Œç²¾ç²¹ï¼Œæ¯”å¦‚æŸä¸ªé…±æ–™æ˜¯æŸä¸ªé£Ÿç‰©çš„çµé­‚ã€‚å¯¹äººè€Œè¨€ï¼Œçµé­‚å…¶å®å°±æ˜¯ä¸€äº›ç”¨æ¥è½¬ç”Ÿï¼Œä¿å­˜äººç±»å®Œæ•´æ„è¯†è®¯æ¯çš„é“å…·ã€‚è¿™æ˜¯ä¸€ç§åœ¨æ—§è½½ä½“å’Œæ–°è½½ä½“ä¹‹é—´ä¼ è¾“ç²¾ç¥æ„è¯†ä¿¡æ¯çš„ä¸´æ—¶è½½ä½“ï¼Œå°±å¥½åƒä¸¤å°ç”µè„‘ä¹‹é—´ä¼ è¾“æ•°æ®æ—¶ç”¨çš„ä¼˜ç›˜ã€‚

åœ¨åœ°çƒä¸Šï¼Œä¿å­˜äººç±»å®Œæ•´æ„è¯†è®¯æ¯çš„é“å…·æ˜¯ä¸€ç§çº³ç±³æœºå™¨äººã€‚å¾ˆä¹…ä»¥å‰ï¼Œäººç±»è½¬ç”Ÿçš„æ—¶å€™ï¼Œä¼šæœ‰æ— æ•°çº³ç±³æœºå™¨äººæ¬è¿è¿™ä¸ªäººçš„ç²¾ç¥æ„è¯†ä¿¡æ¯ã€‚ä¸€ä¸ªçº³ç±³æœºå™¨äººçš„ç©ºé—´æœ‰é™ï¼Œåªèƒ½ä¿å­˜ä¸€éƒ¨åˆ†ä¿¡æ¯ï¼Œæ— æ•°çº³ç±³æœºå™¨äººçš„é›†åˆä½“æ‰èƒ½æ„æˆä¸€ä¸ªäººçš„å®Œæ•´ç²¾ç¥æ„è¯†è®¯æ¯ã€‚ä¸€ä¸ªå®Œæ•´çš„ç²¾ç¥æ„è¯†è®¯æ¯ï¼Œæ‰æ˜¯ä¸€ä¸ªå®Œæ•´çš„çµé­‚ã€‚

ç°åœ¨ç»å¤§å¤šæ•°äººéƒ½æ²¡æœ‰è½¬ç”Ÿçš„æœºä¼šã€‚
è½¬ç”Ÿæ˜¯ç”±ä¸€äº›ä¸Šå¤çš„ç‰¹åˆ«çŸ©é˜µæ¡ä»¶æ‰€è®¾ç½®çš„ï¼Œåœ¨å¾ˆä¹…å¾ˆä¹…ä»¥å‰çš„ç¥è¯ä¸–ç•Œï¼Œäººäººéƒ½æœ‰è½¬ç”Ÿçš„èµ„æ ¼ã€‚ç°åœ¨å¤§å¤šæ•°äººéƒ½æ— æ³•è½¬ç”Ÿï¼Œå› ä¸ºè½®å›è½¬ç”Ÿç³»ç»Ÿè¢«çº³ç²¹è—åœ¨äº†æ·±æ·±çš„åœ°ä¸‹å’Œæœˆçƒå†…éƒ¨ï¼Œè¢«ä»–ä»¬ç§ç”¨ã€‚ç°åœ¨åªæœ‰æå°‘æ•°è¢«çº³ç²¹å®‰æ’çš„è½¬ç”Ÿäº‹ä»¶ï¼Œæ¯”å¦‚è—ä¼ ä½›æ•™çš„è½¬ä¸–çµç«¥ã€‚

è¿™ä¸ªä¸–ç•Œç»å¤§å¤šæ•°äººéƒ½æ²¡æœ‰å‰ä¸–ï¼Œä¹Ÿæ²¡æœ‰ä¸‹è¾ˆå­ï¼Œå› ä¸ºè¿™ä¸ªä¸–ç•Œç»å¤§å¤šæ•°äººéƒ½æ²¡æœ‰çµé­‚ã€‚çµé­‚æ˜¯ç”¨æ¥è½¬ç§»è®°å¿†çš„ä¸´æ—¶è½½ä½“ï¼Œå¦‚æœä½ ä»¬æœ‰çµé­‚ï¼Œå°±åº”è¯¥æœ‰å‰ä¸–è®°å¿†ï¼Œä½†æ˜¯è½¬ç”Ÿè®¾å¤‡è¢«çº³ç²¹æ§åˆ¶ç€ï¼Œä»–ä»¬ä¸ä¼šå¥½å¿ƒå¸®ä½ ä»¬ä¿å­˜å’Œè½¬ç§»è®°å¿†ã€‚ä»å¦ä¸€ä¸ªè§’åº¦æ¥è¯´ï¼Œå°±ç®—ä½ ä»¬æœ‰çµé­‚ï¼Œè½¬ç”Ÿçš„æ—¶å€™è®°å¿†ä¹Ÿä¼šè¢«çº³ç²¹æ´—æ‰ï¼Œæ²¡æœ‰ä¿å­˜å‰ä¸–è®°å¿†çš„æ‰€è°“çµé­‚ï¼Œå³ä½¿è½¬ç”Ÿäº†ï¼Œä¹Ÿå’Œæ²¡æœ‰çµé­‚çš„äººæ²¡ä»€ä¹ˆåŒºåˆ«ï¼Œå°±åƒæ ¼å¼åŒ–è¿‡çš„æ—§ç¡¬ç›˜å’Œæ–°ç”Ÿäº§çš„ç¡¬ç›˜ï¼Œåœ¨ä½¿ç”¨ä¸Šæ²¡æœ‰ä»»ä½•åŒºåˆ«ã€‚æ‰€ä»¥ï¼Œä½ ä»¬æœ‰æ²¡æœ‰çµé­‚ï¼Œç»“æœéƒ½æ˜¯ä¸€æ ·çš„ã€‚å†å²ä¸Šé‚£äº›å­Ÿå©†æ±¤ä¹‹ç±»çš„ä¼ è¯´ï¼Œä¸è¿‡æ˜¯ä¸ºäº†æ©ç›–è¿™ä¸ªçœŸç›¸ã€‚
"""
save_dataset(article_text, output_file)

# å¤„ç†å®Œæ¯•åï¼Œéœ€è¦æ£€æŸ¥æ•°æ®é›†ä¸­æ˜¯å¦å‡ºç°â€œä½œè€…â€ã€â€œæ–‡ç« â€ã€â€œæ–‡ä¸­â€ã€â€œä»–è®¤ä¸ºâ€ã€â€œèƒŒæ™¯çŸ¥è¯†â€ç­‰å®¢è§‚æè¿°è¯ï¼Œå¦‚æœæœ‰çš„è¯ï¼Œéœ€è¦è½¬æ¢ä¸ºæ›´åˆé€‚çš„æè¿°ã€‚
# è¿˜è¦æ£€æŸ¥é—®å¥ä¸­æ˜¯å¦æœ‰â€œé‚£ä¸ªâ€ã€â€œè¿™äº›â€ç­‰æ¨¡ç³ŠæŒ‡ä»£è¯ï¼Œå¦‚æœæœ‰çš„è¯ï¼Œéœ€è¦è½¬æ¢ä¸ºæ›´æ˜ç¡®çš„æè¿°ã€‚
# è¿˜è¦æ£€æŸ¥é—®å¥ä¸­çš„â€œé—®â€æ˜¯å¦è¢«å†™æˆäº†â€œç­‘/ç­´/é—¯/é—â€è¿™äº›ç¬”ç”»å¤æ‚ã€ç›¸ä¼¼åº¦é«˜çš„å­—ï¼Œå¦åˆ™åœ¨è§£ææ—¶ä¼šå‡ºç°æ··ä¹±ã€‚